"""Tool-Based usage example of Agent Skills

This example demonstrates the Tool-Based approach:
LLM uses the 'skill' tool to load instructions, then file_read for resources.

For Filesystem-Based approach, see: 1-basic_usage.py
"""

import asyncio
import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from strands import Agent
from strands_tools import file_read
from agentskills import discover_skills, create_skill_tool, generate_skills_prompt, get_bedrock_agent_model
from utils.strands_stream import TerminalStreamRenderer


def estimate_tokens(text: str) -> int:
    """Rough token estimation (1 token â‰ˆ 4 characters)"""
    return len(text) // 4


def print_section(title: str, phase: str = ""):
    """Print formatted section header"""
    print("\n" + "=" * 70)
    if phase:
        print(f"[{phase}] {title}")
    else:
        print(title)
    print("=" * 70)


async def main():
    """Tool-based usage example with progressive disclosure"""

    print_section("Progressive Disclosure: Tool-Based Usage", "")
    print("\nğŸ¯ Progressive Disclosure (ì ì§„ì  ê³µê°œ): ì´ ì ‘ê·¼ ë°©ì‹ì€ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©ì„ ìµœì†Œí™”í•˜ê³  íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤")
    print("   1. ìµœì†Œí•œì˜ ì´ˆê¸° ë¡œë“œ (Phase 1: ë©”íƒ€ë°ì´í„°ë§Œ)")
    print("   2. ìŠ¤í‚¬ì´ í™œì„±í™”ë  ë•Œë§Œ ì§€ì‹œì‚¬í•­ ë¡œë“œ (Phase 2)")
    print("   3. ì‹¤ì œë¡œ í•„ìš”í•  ë•Œë§Œ ë¦¬ì†ŒìŠ¤ ë¡œë“œ (Phase 3)")
    
    # ========================================================================
    # Phase 1: Discovery - Load only metadata
    # ========================================================================
    print_section("Phase 1: Discovery (ë©”íƒ€ë°ì´í„°ë§Œ)", "PHASE 1")

    skills_dir = Path(__file__).parent.parent / "skills"
    print(f"\nğŸ“‚ ìŠ¤ìº” ì¤‘: {skills_dir}")
    print("â³ ë©”íƒ€ë°ì´í„°ë§Œ ë¡œë“œ ì¤‘ (ì§€ì‹œì‚¬í•­ì´ë‚˜ ë¦¬ì†ŒìŠ¤ëŠ” ë¡œë“œí•˜ì§€ ì•ŠìŒ)...\n")

    skills = discover_skills(skills_dir)

    total_tokens = 0
    print(f"âœ… {len(skills)}ê°œì˜ ìŠ¤í‚¬ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤\n")

    for i, skill in enumerate(skills, 1):
        # Calculate approximate tokens for metadata
        metadata_text = (
            f"{skill.name} {skill.description} "
            f"{skill.license or ''} {skill.compatibility or ''} "
            f"{skill.allowed_tools or ''}"
        )
        tokens = estimate_tokens(metadata_text)
        total_tokens += tokens

        print(f"{i}. ğŸ“¦ {skill.name}")
        print(f"   ì„¤ëª…: {skill.description[:80]}...")
        print(f"   ğŸ“Š ì˜ˆìƒ í† í° ìˆ˜: ~{tokens} í† í°")

        if skill.allowed_tools:
            print(f"   ğŸ”§ í—ˆìš©ëœ ë„êµ¬: {skill.allowed_tools}")
        if skill.compatibility:
            print(f"   âš™ï¸  í˜¸í™˜ì„±: {skill.compatibility}")

        print(f"   ğŸ“ ê²½ë¡œ: {skill.path}")
        print()

    if skills:
        print(f"ğŸ’¡ Phase 1 ì´ê³„: {len(skills)}ê°œ ìŠ¤í‚¬ì— ëŒ€í•´ ~{total_tokens} í† í°")
        print(f"\nâœ“ ë©”íƒ€ë°ì´í„°ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë¡œë“œë¨ (Phase 1 ì™„ë£Œ)")
        print(f"   âœ“ ì§€ì‹œì‚¬í•­ì€ ì•„ì§ ë¡œë“œë˜ì§€ ì•ŠìŒ (Phase 2ì—ì„œ ë¡œë“œ ì˜ˆì •)")
        print(f"   âœ“ ë¦¬ì†ŒìŠ¤ëŠ” ì•„ì§ ë¡œë“œë˜ì§€ ì•ŠìŒ (Phase 3ì—ì„œ ë¡œë“œ ì˜ˆì •)")

    if not skills:
        print("\nâš ï¸  ìŠ¤í‚¬ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'skills/' ë””ë ‰í† ë¦¬ì— ìŠ¤í‚¬ì„ ìƒì„±í•˜ì„¸ìš”.")
        return

    # ========================================================================
    # Phase 1: Generate system prompt with skill metadata
    # ========================================================================
    input("\nâ¸  Press Enter to continue to generate system prompt...")
    print_section("Phase 1: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±", "PHASE 1.5")

    base_prompt = "You are a helpful AI assistant."
    skills_prompt = generate_skills_prompt(skills)
    full_prompt = f"{base_prompt}\n\n{skills_prompt}"

    prompt_tokens = estimate_tokens(full_prompt)
    print(f"\nğŸ“ ìŠ¤í‚¬ ë©”íƒ€ë°ì´í„°ê°€ í¬í•¨ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±ë¨")
    print(f"   ğŸ“Š ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í¬ê¸°: {len(full_prompt)} ë¬¸ì")
    print(f"   ğŸ“Š ì˜ˆìƒ í† í° ìˆ˜: ~{prompt_tokens} í† í°")
    print(f"   âœ“ {len(skills)}ê°œ ìŠ¤í‚¬ì˜ ë©”íƒ€ë°ì´í„° í¬í•¨")
    print(f"\nğŸ“„ ìƒì„±ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸:")
    print(full_prompt)

    # ========================================================================
    # Create agent with skill tool + file_read
    # ========================================================================
    input("\nâ¸  Press Enter to continue to create agent...")
    print_section("ì—ì´ì „íŠ¸ ì´ˆê¸°í™”", "")

    skill_tool = create_skill_tool(skills, skills_dir)
    tool_name = getattr(skill_tool, '__name__', 'skill')
    print(f"\nğŸ”§ ìŠ¤í‚¬ ë„êµ¬ ìƒì„±ë¨: {tool_name}")
    print(f"   âœ“ ì§€ì‹œì‚¬í•­ì´ í•„ìš”í•  ë•Œ LLMì´ í˜¸ì¶œí•  ìˆ˜ ìˆìŒ")
    print(f"   âœ“ LLMì´ skill(skill_name=...)ì„ í˜¸ì¶œí•˜ë©´ Phase 2ê°€ íŠ¸ë¦¬ê±°ë¨")

    agent_model = get_bedrock_agent_model(thinking=True)
    agent = Agent(
        system_prompt=full_prompt,
        tools=[skill_tool, file_read],
        model=agent_model,
        callback_handler=None,  # Disable default callback for custom streaming
    )

    print(f"\nâœ… ì—ì´ì „íŠ¸ê°€ ë‹¤ìŒìœ¼ë¡œ ìƒì„±ë¨:")
    print(f"   - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Phase 1 ë©”íƒ€ë°ì´í„° í¬í•¨)")
    print(f"   - skill ë„êµ¬ (Phase 2 íŠ¸ë¦¬ê±°)")
    print(f"   - file_read ë„êµ¬ (Phase 3 íŠ¸ë¦¬ê±°)")

    # ========================================================================
    # Example 1: Asking about available skills (Phase 1 only)
    # ========================================================================
    input("\nâ¸  Press Enter to continue to example 1...")
    prompt = "ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¤í‚¬ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."

    print_section(f"ì§ˆë¬¸ 1: {prompt}\n : ì´ ì¿¼ë¦¬ëŠ” Phase 1 ë©”íƒ€ë°ì´í„°ë§Œ ì‚¬ìš© (skill ë„êµ¬ í˜¸ì¶œ ë¶ˆí•„ìš”)", "")
    
    renderer = TerminalStreamRenderer()
    async for event in agent.stream_async(prompt):
        renderer.process(event)
    print()

    # ========================================================================
    # Example 2: LLM will use skill tool to load instructions (Phase 2)
    # ========================================================================
    input("\nâ¸  Press Enter to continue to example 2...")

    if skills:
        prompt = f"{skills[0].name} ìŠ¤í‚¬ì€ ì–´ë–»ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?"
        print_section(f"ì§ˆë¬¸ 2: {prompt}\n : ì´ ì¿¼ë¦¬ëŠ” Phase 2ë¥¼ íŠ¸ë¦¬ê±°í•¨ (skill ë„êµ¬ í˜¸ì¶œ)", "")

        renderer.reset()
        async for event in agent.stream_async(prompt):
            renderer.process(event)
        
        print()


if __name__ == "__main__":
    asyncio.run(main())
